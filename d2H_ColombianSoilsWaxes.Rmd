---
title: "d2H_ColombianSoilsWaxes_V1"
subtitle: "Analyses from September 2019"
author: "Lina Perez-Angel <lina.perezangel@colorado.edu>"
date: "`r Sys.Date()`"
output: 

 html_document:
    code_folding: show
    df_print: paged
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
editor_options:
  chunk_output_type: console 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#Summary

Data processing for hydrogen isotopes in plant waxes from soils (10 cm depth) in the Eastern Cordillera of Colombia. 


# Load packages

```{r, message=FALSE, warning=FALSE}
library(tidyverse) # general data wrangling and plotting
library(isoreader) # reading the raw data files
library(isoprocessor) # processing the data
library(plotly)
```

# read files 

```{r}
data_path_0919 <- iso_read_continuous_flow("data_d2H_waxes") %>% iso_filter_files_with_problems()
iso_files_raw <- data_path_0919
```

```{r}
  #save the data in .cf.rds form, so it doesn't take forever to download next time
  iso_save(iso_files_raw, file = "1909_LP_n-alkanes_H_soils")
```


## Process file information (*)

```{r}
# process file information
iso_files_d2H <- iso_files_raw %>% 
  # rename key file info columns
  iso_rename_file_info(id1 = `Identifier 1`, id2 = `Identifier 2`) %>% 
  # parse text info into numbers
  iso_parse_file_info(number = c(Analysis, `H3 Factor`)) %>% 
  # process other file information that is specific to the naming conventions
  # of this particular sequence
  iso_mutate_file_info(
    # what is the type of each analysis?
    type = case_when(
      str_detect(id1, "[Zz]ero")      ~ "on_off",
      str_detect(id1, "H3")           ~ "H3",
      str_detect(id1, "A6")           ~ "std",
      TRUE                            ~ "sample"
    ),
    # what folder are the data files in? (assuming folder = sequence)
    folder = basename(dirname(file_path)),
    # fix typos in id1 learn to use case_when() to modify things in the dataframe from typos when running the samples
    id1 = case_when(
      id1 == "OG446" ~ "OG446-250020-1",
      id1 == "OG428-250026-1" ~ "OG428-250039-1",
      TRUE ~ id1
    ),
    # sample name
    name = str_extract(id1, "^[^_]+"),
    # which solvent is used
    solvent = str_extract(file_id, "(100|50)\\%[^_.]+") %>% { ifelse(is.na(.), "100%hexane", .) },
    # what was the injection volume based on the AS method name?
    injection_volume.uL = str_extract(`AS Method`, "AS PTV [0-9.]+") %>% 
      parse_number(),
    # what was the concentration? (assuming Preparation = concentration or volume)
    conc.ng_uL = str_extract(Preparation, "[0-9.]+?ng( per |/)ul") %>% parse_number(),
    # combined label
    label = sprintf("%s (#%d)", name, Analysis)
   
    )
   
  # focus only on the relevant file info, discarding the rest
  iso_select_file_info(iso_files_d2H, 
    Analysis, id1, id2, folder, file_datetime, name, label, type, 
    injection_volume.uL, conc.ng_uL, solvent, process, `H3 Factor`
  ) 
```

```{r}
print(iso_files_d2H$BF5095__OG446_replicate.dxf$file_info$id1)
```

## Show file information

```{r}
# display file information
iso_files_d2H %>% iso_get_file_info() %>% select(-file_id, -folder) %>% knitr::kable()
```

## Example chromatograms

```{r "example_chromatograms", fig.width=8, fig.height=8}
iso_files_d2H %>% 
  # select a few analyses (these #s must exist!)
  iso_filter_files(Analysis %in% c(5097, 5099)) %>% 
  #iso_filter_files(Analysis %in% c(3384, 3387, 3401)) %>% 
  # plot the chromatograms
  iso_plot_continuous_flow_data(
    # select data and aesthetics
    data = c(2), color = id1, panel = Analysis,
    # zoom in on time interval
    #time_interval = c(1000, 3200)
  ) +
  # customize resulting ggplot
  theme(legend.position = "bottom")
```

## use interactive plot
```{r, eval=TRUE, fig.width=7, fig.height=6}
# optinally, use an interactive plot to explore your data
# - make sure you install the plotly library --> install.packages("plotly")
# - switch to eval=TRUE in the options of this chunk to include in knit
# - this should work for all plots in this example processing file
library(plotly)
ggplotly(dynamicTicks = TRUE)
```


# ON/OFFs

```{r "on_off_chromatograms", fig.width=8, fig.height=4}
# find files with zero in the Identifier 1 field
on_offs <- iso_files_d2H %>% iso_filter_files(type == "on_off") 

# visualize the on/offs  
on_offs %>% iso_plot_continuous_flow_data(data = 2, color = id2)
```


## Summary

```{r "on_off_summary", fig.width=6, fig.height=4}
# calculate on/off summary
on_off_summary <- 
  on_offs %>% 
  # retrieve data table
  iso_get_vendor_data_table(
    select = c(`Ampl 2 [mV]`, `Intensity 2 [Vs]`, `d 2H/1H [permil]`),
    include_file_info = c(file_datetime, id2),
    with_units = TRUE
  ) %>% 
  # summarize information
  group_by(file_datetime, id2) %>% 
  iso_summarize_data_table()

# table
on_off_summary %>% knitr::kable(digits = 3)
# plot
on_off_summary %>% 
  # use generic data plot function
  iso_plot_data(
    x = file_datetime, y = `d 2H/1H [permil] sd`,
    size = `Ampl 2 [mV] mean`, color = id2,
    points = TRUE
  ) + 
  # customize resulting ggplot
  expand_limits(y = 0) +
  scale_x_datetime(NULL, date_labels = "%b %d - %H:%M") 
```


# H3 Factor

```{r "H3_factor_chromatograms", fig.width=8, fig.height=4}
# find files with linearity in the Identifier 1 field
H3s <- iso_files_d2H %>% iso_filter_files(type == "H3") 

# visualize the linearity runs
H3s %>% iso_plot_continuous_flow_data(data = 2, color = format(file_datetime))
```

## Summary

Even though I only ran H3 factor on Sept 24, the H3 factor of the sequence before (190924_H_Fames_ND) and after (191004_191004_H_GDGTalkyls_JM_10.04.19) mine is ~11, so the H3 factor remain consistent through all my runs 
```{r "H3_factor_summary", fig.width=8, fig.height=6}
# calculate H3 factor summary
H3_summary <- 
  H3s %>% 
  iso_get_vendor_data_table(
    select = c(`Ampl 2 [mV]`),
    include_file_info = c(folder, file_datetime, Analysis, `H3 Factor`),
    with_units = TRUE
  ) %>% 
  group_by(folder, file_datetime, Analysis, `H3 Factor`) %>% 
  summarize(`min Ampl 2 [mV]` = min(`Ampl 2 [mV]`), 
            `max Ampl 2 [mV]` = max(`Ampl 2 [mV]`))

# table
H3_summary

# plot
H3_summary %>% 
  iso_plot_data(
    x = file_datetime,  
    y = c(`H3 Factor`, `max Ampl 2 [mV]`, `min Ampl 2 [mV]`),
    label = Analysis,
    color = folder,
    points = TRUE, lines = FALSE
  ) +
  scale_x_datetime(NULL, date_labels = "%b %d - %H:%M") 
```

# Data table (*)

```{r}
# retrieve the peak data table
peak_table_0919 <- iso_files_d2H %>% 
  # focus on standards and samples only
  iso_filter_files(type %in% c("std", "sample")) %>% 
  # discard files without peak maps or di dnot inject or something went wrong
  iso_filter_files(!Analysis %in% c(4998, 4999, 5000, 5006, 5008, 5012, 5014, 5018, 5051, 5073, 5001)) %>% 
  # retrieve peak data table from vendor data
  iso_get_vendor_data_table(
    select = c(
      is_ref = `Is Ref.?`,
      rt_start = Start, rt = Rt, rt_end = End,
      amp2.mV = `Ampl 2`, amp3.mV = `Ampl 3`,
      area2.Vs = `Intensity 2`, area3.Vs = `Intensity 3`, area.Vs = `Intensity All`,
      ratio = `R 3H2/2H2`, d2H = `d 2H/1H`
    ),
    include_file_info = everything()
  ) %>%
  # bring in Analysis # order
  arrange(Analysis) 
```

# Peak Identification
## Load peak maps

```{r}
# this information is often maintained in a csv or Excel file instead
# but generated here from scratch for demonstration purposes
peak_maps_d2H <- readxl::read_excel("d2H_SoilWaxes_peaks_maps.xlsx")
peak_maps_d2H %>% knitr::kable(digits = 0)

```


## Identify peaks (*)

```{r}
# get all data vendor data table, map peaks, calculate averages, add known dDs
peak_table_0919_w_ids <- 
  peak_table_0919 %>% 
  # map peaks
  iso_map_peaks(
    # provide peak maps
    peak_maps = peak_maps_d2H,
    # specify which file info columns identify an individual file
    file_id = c(file_id, Analysis),
    # specify which file info column identifies the peak map to use for each file
    map_id = type
  ) 
```


## Inspect peak mappings

```{r "example_chromatograms_with_peaks", fig.width = 8, fig.height = 8}
# use same plotting as earlier, except now with peak features added in
iso_files_d2H %>% 
  # select the example chromatograms again
  iso_filter_files(Analysis %in% c(5030, 5031, 5036, 5037, 5095)) %>% 
  iso_plot_continuous_flow_data(
    # select data and aesthetics
    data = c(2), color = id1, panel = Analysis,
    # zoom in on time interval
    time_interval = c(1000, 3500),
    # provide peak table information
    peak_table = peak_table_0919_w_ids,
    # define peak labels, this can be any valid expression
    peak_label = paste0(peak_info, "\nd2H=", round(d2H, 1)), 
    peak_label_size = 2,
    # specify which labels to show (removing the !is_identified or putting a 
    # restriction by retention time can help a lot with busy chromatograms)
    peak_label_filter = is_identified | !is_identified | is_missing
  )  +
  # customize resulting ggplot
  theme(legend.position = "bottom")

```

## Overview of unclear peak mappings

```{r, eval = FALSE}
# look at missing and unidentified peaks summary (not run during knitting)
# -> check if any of the missing peaks are unexpected (should be there but aren't)
# -> check if any unidentified peaks should be added to the peak maps
# -> check if any ambiguous peaks need clearer peak map retention times
# when in doubt, look at the chromatograms of the problematic files!
# as needed: iterate on peak map update, then peak mapping inspection
peak_table_0919_w_ids %>% 
  iso_get_problematic_peak_mappings() %>% 
  iso_summarize_peak_mappings(file_id = c(Analysis, type)) %>% 
  View()
```

# Reference peaks

```{r "ref_peak_variation", fig.width=10, fig.height=4}
# examine variation in the reference peaks
peak_table_0919_w_ids %>% 
  # focus on reference peaks only
  filter(!is.na(ref_nr)) %>% 
  # mark ref peak used for raw delta values (assuming the same in all anlysis)
  mutate(ref_info = paste0(ref_nr, ifelse(is_ref == 1, "*", "")) %>% 
           factor() %>% fct_inorder()) %>% 
  # calculate deviations from average measured ratio in each file
  group_by(file_id) %>% 
  mutate(delta_vs_avg = (ratio / mean(ratio) - 1) * 1000) %>% 
  ungroup() %>% 
  # visualize
  ggplot() +
  aes(factor(Analysis), delta_vs_avg, fill = factor(ref_info)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5),
        strip.text = element_text(size = 6, hjust = 0)) +
  labs(x = "Analysis", y = "Deviation from run average (permil)", 
       color = "Reference\npeak", fill = "Reference\npeak") # +
  ## optional addition: panel by folder/seq
  # facet_grid(. ~ folder, scale = "free_x", space = "free_x")
```
# Analyte peaks

## Select analyte peaks (*)
```{r}
# focus on analyte peaks and calculate useful summary statistics
peak_table_0919_analytes <- peak_table_0919_w_ids %>% 
  # omit reference peaks for further processing (i.e. analyte peaks only)
  filter(is.na(ref_nr)) %>% 
  # for each analysis, calculate a few useful summary statistics
  group_by(file_id) %>%
  mutate(
   # calculate relative area (without IS) for individual peaks 
    rel_area = area.Vs / sum(area.Vs[is.na(compound) | compound != "Cholestane (alpha-5)"], na.rm = TRUE),
    # calculate mean area for all peaks
    mean_area.Vs = mean(area.Vs, na.rm = TRUE),
    # calculate mean area and amplitude for identified peaks
    mean_area_identified.Vs = mean(area.Vs[!is.na(compound)], na.rm = TRUE),
    mean_amp_identified.mV = mean(amp2.mV[!is.na(compound)], na.rm = TRUE)
  ) %>%
  ungroup()
```
## First look
```{r "first_look_sample_and_standard_peaks", fig.width=7, fig.height=6}
peak_table_0919_analytes %>% 
  # focus on identified peaks (comment out this line to see ALL peaks)
  filter(!is.na(compound)) %>% 
  # visualize with convenience function iso_plot_data
  iso_plot_data(
    # choose x and y (multiple y possible)
    x = area.Vs, y = c(amp2.mV, d2H),
    # choose aesthetics
    color = compound, shape = type, label = compound, size = 3,
    # decide what geoms to include
    points = TRUE
  ) +
  # further customize ggplot with a log scale x axis
  scale_x_log10()
```

## Optionally - use interactive plot
```{r, eval=TRUE, fig.width=7, fig.height=6}
# optinally, use an interactive plot to explore your data
# - make sure you install the plotly library --> install.packages("plotly")
# - switch to eval=TRUE in the options of this chunk to include in knit
# - this should work for all plots in this example processing file
library(plotly)
ggplotly(dynamicTicks = TRUE)
```

## Evaluate signal yield
```{r "yield", fig.width=7, fig.height=6}
# evaluate yield
# (only makes sense if both injection volume and concentration are available)
peak_table_0919_analytes %>% 
  # focus on standards
  filter(type == "std") %>% 
  # calculate injection amount
  mutate(injection.ng = injection_volume.uL * conc.ng_uL) %>% 
  # visualize
  iso_plot_data(
    # x and y
    x = injection.ng, y = c(mean_area_identified.Vs, mean_amp_identified.mV),
    # aesthetics
    color = factor(injection_volume.uL), shape = factor(conc.ng_uL), size = file_datetime,
    points = TRUE
  ) +
  # modify plot with trendline and axis limits
  geom_smooth(method = "lm", mapping = aes(color = NULL, shape = NULL)) +
  expand_limits(y = 0, x = 0)
```
# Isotope standard values
## Load isotope standards

```{r}
# this information is often maintained in a csv or Excel file instead
# but generated here from scratch as the info was on the web
standards <- 
  tibble::tribble(
    ~compound,   ~true_d2H,
    "nC16",			-9.1,
    "nC17",			-117.8,
    "nC18",			-52,
    "nC19",			-56.3,
    "nC20",			-89.7,
    "nC21",			-177.8,
    "nC22",			-81.3,
    "nC23",			-67.2,
    "nC24",			-29.7,
    "nC25",			-263,
    "nC26",			-45.9,
    "nC27",			-172.8,
    "nC28",			-36.8,
    "nC29",			-177.8,
    "nC30",			-213.6
  ) %>% mutate(type = "std")
standards %>% knitr::kable(digits = 2)
```
## Add isotope standards (*)

```{r}
peak_table_0919_w_stds <- 
  peak_table_0919_analytes %>% 
  iso_add_standards(stds = standards, match_by = c("type", "compound")) 
```

# Calibration

## Single analysis calibration (for QA)

### Generate calibrations

Determine calibrations fits for all individual standard analyses.

```{r}
stds_w_calibs <- peak_table_0919_w_stds %>%
  # focus on standards
  filter(type == "std") %>% 
  # remove unassigned peaks
  iso_remove_problematic_peak_mappings() %>% 
  # prepare for calibration by defining the grouping column(s) 
  iso_prepare_for_calibration(group_by = Analysis) %>% 
  # run calibration
  iso_generate_calibration(
    model = c(
      linear = lm(d2H ~ true_d2H)
      #, with_baseline_drift = lm(d2H ~ true_d2H + area.Vs)
    )
  ) %>% 
  # unnest some useful file information for visualization
  iso_get_calibration_data(
  #iso_unnest_data(
    select = c(folder, file_datetime, injection_volume.uL, solvent, mean_area_identified.Vs))
# check for problematic calibrations
stds_w_calibs %>% iso_get_problematic_calibrations() -> problematic.calibs
# View(problematic.calibs)
# move forward only with good calibrations
stds_w_calibs <- stds_w_calibs %>% iso_remove_problematic_calibrations()
```

### Coefficients

in this case I set the threshold in 5 (is this ok? normal for Hydrogen? it seems that most of the runs are under this value...)
```{r "single_analysis_calibration_coefficients", fig.width=7, fig.height=8}

# visualize the calibration coefficients
stds_w_calibs %>% 
  iso_plot_calibration_parameters(
    # x-axis, could also be e.g. Analysis or file_datetime (also use date_breaks!)
    x = mean_area_identified.Vs,
    # aesthetics
   shape = calib,
    color = calib, size = mean_area_identified.Vs
  ) + 
  # highlight RSD threshold (0.5 is fairly liberal, can be stricter!)
  geom_hline(tibble(term = factor("RSD"), threshold = 5),
             mapping = aes(yintercept = threshold), linetype = 2)
```

### Residuals

```{r "single_analysis_residuals", fig.width=7, fig.height=6}
stds_w_calibs %>% 
  # pull out all peak data to including residuals
  #iso_unnest_data(select = everything()) %>% 
  iso_get_calibration_data(select = everything()) %>% 
  # focus on standard peaks
  filter(is_std_peak) %>% 
  # calculate parameters to visualize
  group_by(Analysis) %>% 
  mutate(
    `Var: residual [permil]` = resid,
    `Var: area diff from mean [%]` = (area.Vs/mean(area.Vs) - 1) * 100
  ) %>%
  ungroup() %>% 
  # visualize
  iso_plot_data(
    # x and y 
    x = compound, y = starts_with("Var"),
    # grouping and aesthetics
    group = paste(Analysis, calib), color = calib, linetype = calib,
    # geoms
    lines = TRUE
  ) + 
  facet_grid(panel ~ calib, scales = "free_y")
```

# Global Calibration with all standards

## 4V Generate calibrations (*)
```{r}
# define a global calibration across all standards
global_calibs <- 
  peak_table_0919_w_stds %>%
  # remove (most) problematic peaks to speed up calibration calculations
  # note: could additionally remove unidentified peaks if they are of no interest
  iso_remove_problematic_peak_mappings(remove_unidentified = FALSE) %>% 
  # prepare for calibration (no grouping to go across all analyses)
  iso_prepare_for_calibration() %>% 
  # run different calibrations
  iso_generate_calibration(
    model = c(
     # linear = lm(d2H ~ true_d2H), #these are all the different combinations of things you can correct for as a global claibration, linear is the standard one
      #with_rt = lm(d2H ~ true_d2H + rt), #because my samples have a systematic errror due to retention time, we applied this
      #with_datetime = lm(d2H ~ true_d2H + file_datetime),
     # with_rt_area_datetime = lm(d2H ~ true_d2H + file_datetime + rt + area2.Vs),
      #with_area_and_rt = lm(d2H ~ true_d2H + area2.Vs + rt), #it seems that this one is the best one as the retention time affects the area Vs and i need to correct for both
      with_area = lm(d2H ~ true_d2H + area2.Vs),
     with_area_divide = lm(d2H ~ true_d2H + (1/ area2.Vs)),
     with_area_cross_divide = lm(d2H ~ true_d2H * (1/ area2.Vs)),
     with_area_sqrt = lm(d2H ~ true_d2H + sqrt(area2.Vs)),
      with_area_cross_sqrt = lm(d2H ~ true_d2H * sqrt(area2.Vs)),
      with_area_cross = lm(d2H ~ true_d2H * area2.Vs)
    ),
    # specify which peaks to include in the calibration, here:
    # - all std_peaks (this filter should always be included!)
    # - standard peaks between 5 and 100 Vs
    # - only analyses with seed oxidation (same as all the samples)
    is_std_peak = is_std_peak & area.Vs > 4 & area.Vs < 100
  )
```
### Coefficients

```{r "global_calibration_coefficients_4V", fig.width=7, fig.height=12}
# look at coefficients and summary
global_calibs %>% 
  # unnest calibration parameters
  iso_get_calibration_parameters(
    select_from_coefs = 
      c(term, estimate, SE = std.error, signif),
    select_from_summary = 
      c(fit_R2 = adj.r.squared, fit_RMSD = deviance, residual_df = df.residual)) %>%
  iso_remove_list_columns() %>% 
  arrange(term) %>% 
  knitr::kable(digits = 4)
# visualize coefficients for the different global calibrations
global_calibs %>% iso_plot_calibration_parameters(x = calib, color = signif)
```
according to this, I think the best calibration is "with_are_cross_sqrt"... is this ok? 

### Residuals
```{r "global_calibration_residuals_4V", fig.width=8, fig.height=4}
global_calibs %>% 
  # pull out all peak data to including residuals
  iso_get_calibration_data(select = everything()) %>% 
  # focus on standard peaks included in the calibration
  filter(in_calib) %>% 
  # visualize
  iso_plot_data(
    # aesthetics
    x = compound, y = resid, color = calib, group = paste(Analysis, calib),
    # geoms
    lines = TRUE
  ) +
  # plot modifications
  facet_grid(. ~ calib) + theme(legend.position = "bottom")
```
based on the residuals, in general, they are pretty similar (I think? I don't see a huge change compared with what I saw with the carbon data)

### Pick global calibration
```{r}
# which calibration to use? can include multiple if desired to see the result

calib_to_use <- "with_area_cross_sqrt" #in this case I need to correct for  retention time (RT), AREA, and datetime? it seems to be the best calibration to use
```
### Apply global calibration (*)

```{r, cache=TRUE}
# note that depending on the number of data points, this may take a while
# for faster calculations, chose calculate_error = FALSE
global_calibs_applied <- 
  global_calibs %>% 
  # decide which calibration to apply based on 
  filter(calib %in% calib_to_use) %>% 
  # apply calibration indication what should be calcculated
  iso_apply_calibration(true_d2H, calculate_error = TRUE)
# calibration ranges
global_calibs_with_ranges <-
  global_calibs_applied %>% 
  # evaluate calibration range for the measured area.Vs and predicted d13C
  iso_evaluate_calibration_range(area.Vs, true_d2H_pred) 
# show calibration ranges
global_calibs_with_ranges %>% 
  iso_unnest_calibration_range() %>% 
  iso_remove_list_columns() %>% 
  knitr::kable(d = 2)
# create calibrated peak table
peak_table_calibrated <- global_calibs_with_ranges %>% 
  iso_unnest_data(select = everything())
```

## Evaluation

### Overview of all the data

```{r "data_overview_all_4V", fig.width=7, fig.height=9}
# replicate earlier overview plot but now with the calibrated delta values
# and with a higlight of the calibration ranges and which points are in range
peak_table_calibrated  %>% 
  # focus on identified peaks (comment out this line to see ALL peaks)
  filter(!is.na(compound)) %>% 
  #filter(compound %in% c("nC29", "nC31", "Cholestane (alpha-5)")) %>% 
  # visualize with convenience function iso_plot_data
  iso_plot_data(
    # choose x and y (multiple y possible)
    x = area.Vs, y = true_d2H_pred,
    # choose aesthetics
    color = in_range, shape = type, label = compound, size = 3,
    # decide what geoms to include
    points = TRUE
  ) %>% 
  # highlight calibration range
  iso_mark_calibration_range() +
  # further customize ggplot with a log scale x axis
  scale_x_log10() +
  # legend
  theme(legend.position = "bottom", legend.direction = "vertical")
```

### Overview of C29, C31, and Cholestane

```{r "data_overview_4V", fig.width=7, fig.height=9}
# replicate earlier overview plot but now with the calibrated delta values
# and with a higlight of the calibration ranges and which points are in range
peak_table_calibrated  %>% 
  # focus on identified peaks (comment out this line to see ALL peaks)
  #filter(!is.na(compound)) %>% 
  filter(compound %in% c("nC29", "nC31", "Cholestane (alpha-5)")) %>% 
  # visualize with convenience function iso_plot_data
  iso_plot_data(
    # choose x and y (multiple y possible)
    x = area.Vs, y = true_d2H_pred,
    # choose aesthetics
    color = in_range, shape = type, label = compound, size = 3,
    # decide what geoms to include
    points = TRUE
  ) %>% 
  # highlight calibration range
  iso_mark_calibration_range() +
  # further customize ggplot with a log scale x axis
  scale_x_log10() +
  # legend
  theme(legend.position = "bottom", legend.direction = "vertical")
```

### Standards

```{r "standards_4V", fig.width=7, fig.height=6}
# visualize how standard line up after calibration
peak_table_calibrated %>% 
  # focus on peaks in calibration
  filter(in_calib) %>% 
  # visualize
  iso_plot_data(
    # x and y
    x = true_d2H, y = true_d2H_pred, y_error = true_d2H_pred_se,
    # aesthetics
    color = compound, size = area.Vs,
    # geoms
    points = TRUE
  ) +
  # add 1:1 trendline
  geom_abline(slope = 1, intercept = 0)
```

### Data

#### Isotopic values

```{r "samples_4V", fig.width = 10, fig.height = 7}
# Warning: data outside the calibration range MUST be taken with a big
# grain of salt, especially at the low signal area/amplitude end
peak_table_calibrated %>% 
  # focus on samples
  filter(type == "sample") %>% 
  # focus on the compuonds we care about
  filter(compound %in% c("nC29", "nC31", "Cholestane (alpha-5)")) %>% 
  # focus on identified peaks (comment out this line to see ALL peaks)
  # if there's a lot of data, might need to hone in on a few at a time
  filter(!is.na(compound)) %>% 
  # visualize
  iso_plot_data(
    # x and y
    x = id1, y = true_d2H_pred, y_error = true_d2H_pred_se,
    # aesthetics
    color = in_range, size = rel_area,
    # geoms
    points = TRUE
  ) %>% 
  # mark calibration range (include optionally)
  iso_mark_calibration_range() +
  # add facet wrap
  facet_wrap(~compound, scales = "free_y") +
  # color palette (here example of manual: www.google.com/search?q=color+picker)
  # scale_color_manual(
  #   values = c("#984EA3", "#E41A1C", "#E41A1C", "#377EB8", "#FF7F00", "#4DAF4A")
  # ) +
  # clarify size scale
  scale_size_continuous(breaks = c(0.01, 0.05, 0.1, 0.2, 0.3), 
                        labels = function(x) paste0(100*x, "%")) +
  # plot labels
  labs(x = NULL, y = "d2H [permil]")

#ggplotly(ggplot2::last_plot() + theme(legend.position = "none"))


```

I made all my calculations of concentrations based on n-alkane C-31, all of the runs are "in range"... so this is good right?? for C29 there are only 4 samples out of range from all the runs I did... so doesn't seem to be that bad?? 

#### Internal Standard check

```{r}
#wasn't able to plot the mean so extracted from dataframe the number
internal_std <- peak_table_calibrated %>% 
  filter(type == "sample") %>% 
  filter(compound == "Cholestane (alpha-5)") 

y_value <- mean(internal_std$true_d2H_pred)
y_value_sd <- sd(internal_std$true_d2H_pred)
# plot IS only
peak_table_calibrated %>% 
  filter(type == "sample") %>% 
  filter(compound == "Cholestane (alpha-5)") %>% 
 iso_plot_data(
    #dt = internal_std,
    x = id1,
    y = true_d2H_pred,
    y_error = true_d2H_pred_se, 
    size = area.Vs, color = in_range,
    points = TRUE, lines = TRUE) + geom_hline(
    mapping = aes(yintercept = y_value)) 



print(paste("mean isotopic value of Cholestane (alpha-5): ", y_value))
print(paste("and the standard deviation value of Cholestane (alpha-5): ", y_value_sd))
#mean(internal_std$true_d2H_pred), mapping =  aes(yintercept =internal_std$true_d2H_pred))
#+
 # geom_hline(data = function(df) 
  #  df %>% group_by(panel) %>% 
 #     summarize(y_value = mean(y_value)),
#    mapping = aes(yintercept = y_value)) +
#  geom_label(data = function(df) 
 #   df %>% group_by(panel) %>% 
  #    summarize(id1 = sort(id1)[1], y_value_sd = sd(y_value), y_value = mean(y_value)),
  #  mapping = aes(color = NULL, label = sprintf("%.2f +/- %.2f", y_value, y_value_sd))
 # )

```


#### Relative abundances

```{r "abundances_4V", fig.width = 7, fig.height = 6, warning=FALSE}
# visualize relative abundances
peak_table_calibrated %>% 
  # focus on samples
  filter(type == "sample") %>% 
  filter(compound %in% c("nC29", "nC31", "nC33")) %>% 
  # focus on identified peaks (comment out this line to see ALL peaks)
  #filter(!is.na(compound)) %>% 
  # visualize
  iso_plot_data(
    # x and y
    x = id1, y = rel_area,
    # aesthetics
    fill = compound
  ) +
  # barchart
  geom_bar(stat = "identity") +
  # scales
  scale_y_continuous(labels = function(x) paste0(100*x, "%"), expand = c(0, 0)) +
  # plot labels
  labs(x = NULL, y = "Relative abundance (by area)")
```

#### Summary

```{r}
# generate data summary
peak_data <- 
  peak_table_calibrated %>% 
  # focus on identified peaks in the samples
  filter(type == "sample", !is.na(compound)) %>% 
  select(id1, compound, Analysis, 
         area.Vs, true_d2H_pred, true_d2H_pred_se, in_range) %>% 
  arrange(id1, compound, Analysis)
# summarize replicates
# this example data set does not contain any replicates but typically all
# analyses should in which case a statistical data summary can be useful
peak_data_summary <- 
  peak_data %>% 
  # here: only peaks within the area calibration range are included
  # you have to explicitly decide which peaks you trust if they are out of range
  filter(
    in_range %in% c("in range", "<'true_d2H_pred' range", ">'true_d2H_pred' range") |
      area.Vs > 4
  ) %>% 
  # summarize for each sample and compound
  group_by(id1, compound) %>% 
  iso_summarize_data_table(area.Vs, true_d2H_pred)
peak_data_summary %>% knitr::kable(d = 2)
```

## Export 4V

```{r}
# export the global calibration with all its information and data to Excel
global_calibs_with_ranges %>% 
 
  iso_export_calibration_to_excel(
   filepath = format(Sys.Date(), "%Y%m%d_d2H_waxes_soils_4V.xlsx"),
     # include data summary as an additional useful tab
     `data summary` = peak_data_summary
   )

```

## 7V Generate calibrations (7V*)
```{r}
# define a global calibration across all standards
global_calibs <- 
  peak_table_0919_w_stds %>%
  # remove (most) problematic peaks to speed up calibration calculations
  # note: could additionally remove unidentified peaks if they are of no interest
  iso_remove_problematic_peak_mappings(remove_unidentified = FALSE) %>% 
  # prepare for calibration (no grouping to go across all analyses)
  iso_prepare_for_calibration() %>% 
  # run different calibrations
  iso_generate_calibration(
    model = c(
     # linear = lm(d2H ~ true_d2H), #these are all the different combinations of things you can correct for as a global claibration, linear is the standard one
      #with_rt = lm(d2H ~ true_d2H + rt), #because my samples have a systematic errror due to retention time, we applied this
      #with_datetime = lm(d2H ~ true_d2H + file_datetime),
     # with_rt_area_datetime = lm(d2H ~ true_d2H + file_datetime + rt + area2.Vs),
      #with_area_and_rt = lm(d2H ~ true_d2H + area2.Vs + rt), #it seems that this one is the best one as the retention time affects the area Vs and i need to correct for both
      with_area = lm(d2H ~ true_d2H + area2.Vs),
     with_area_divide = lm(d2H ~ true_d2H + (1/ area2.Vs)),
     with_area_cross_divide = lm(d2H ~ true_d2H * (1/ area2.Vs)),
     with_area_sqrt = lm(d2H ~ true_d2H + sqrt(area2.Vs)),
      with_area_cross_sqrt = lm(d2H ~ true_d2H * sqrt(area2.Vs)),
      with_area_cross = lm(d2H ~ true_d2H * area2.Vs)
    ),
    # specify which peaks to include in the calibration, here:
    # - all std_peaks (this filter should always be included!)
    # - standard peaks between 5 and 100 Vs
    # - only analyses with seed oxidation (same as all the samples)
    is_std_peak = is_std_peak & area.Vs > 7 & area.Vs < 100
  )
```
### Coefficients

```{r "global_calibration_coefficients_7V", fig.width=7, fig.height=12}
# look at coefficients and summary
global_calibs %>% 
  # unnest calibration parameters
  iso_get_calibration_parameters(
    select_from_coefs = 
      c(term, estimate, SE = std.error, signif),
    select_from_summary = 
      c(fit_R2 = adj.r.squared, fit_RMSD = deviance, residual_df = df.residual)) %>%
  iso_remove_list_columns() %>% 
  arrange(term) %>% 
  knitr::kable(digits = 4)
# visualize coefficients for the different global calibrations
global_calibs %>% iso_plot_calibration_parameters(x = calib, color = signif)
```
according to this, I think the best calibration is "with_are_cross_sqrt"... is this ok? 

### Residuals
```{r "global_calibration_residuals_7V", fig.width=8, fig.height=4}
global_calibs %>% 
  # pull out all peak data to including residuals
  iso_get_calibration_data(select = everything()) %>% 
  # focus on standard peaks included in the calibration
  filter(in_calib) %>% 
  # visualize
  iso_plot_data(
    # aesthetics
    x = compound, y = resid, color = calib, group = paste(Analysis, calib),
    # geoms
    lines = TRUE
  ) +
  # plot modifications
  facet_grid(. ~ calib) + theme(legend.position = "bottom")
```
based on the residuals, in general, they are pretty similar (I think? I don't see a huge change compared with what I saw with the carbon data)

### Pick global calibration
```{r}
# which calibration to use? can include multiple if desired to see the result

calib_to_use <- "with_area_cross_sqrt" #in this case I need to correct for  retention time (RT), AREA, and datetime? it seems to be the best calibration to use
```
### Apply global calibration (*)

```{r, cache=TRUE}
# note that depending on the number of data points, this may take a while
# for faster calculations, chose calculate_error = FALSE
global_calibs_applied <- 
  global_calibs %>% 
  # decide which calibration to apply based on 
  filter(calib %in% calib_to_use) %>% 
  # apply calibration indication what should be calcculated
  iso_apply_calibration(true_d2H, calculate_error = TRUE)
# calibration ranges
global_calibs_with_ranges <-
  global_calibs_applied %>% 
  # evaluate calibration range for the measured area.Vs and predicted d13C
  iso_evaluate_calibration_range(area.Vs, true_d2H_pred) 
# show calibration ranges
global_calibs_with_ranges %>% 
  iso_unnest_calibration_range() %>% 
  iso_remove_list_columns() %>% 
  knitr::kable(d = 2)
# create calibrated peak table
peak_table_calibrated <- global_calibs_with_ranges %>% 
  iso_unnest_data(select = everything())
```

## Evaluation

### Overview of all the data

```{r "data_overview_all_7V", fig.width=7, fig.height=9}
# replicate earlier overview plot but now with the calibrated delta values
# and with a higlight of the calibration ranges and which points are in range
peak_table_calibrated  %>% 
  # focus on identified peaks (comment out this line to see ALL peaks)
  filter(!is.na(compound)) %>% 
  #filter(compound %in% c("nC29", "nC31", "Cholestane (alpha-5)")) %>% 
  # visualize with convenience function iso_plot_data
  iso_plot_data(
    # choose x and y (multiple y possible)
    x = area.Vs, y = true_d2H_pred,
    # choose aesthetics
    color = in_range, shape = type, label = compound, size = 3,
    # decide what geoms to include
    points = TRUE
  ) %>% 
  # highlight calibration range
  iso_mark_calibration_range() +
  # further customize ggplot with a log scale x axis
  scale_x_log10() +
  # legend
  theme(legend.position = "bottom", legend.direction = "vertical")
```

### Overview of C29, C31, and Cholestane

```{r "data_overview_7V", fig.width=7, fig.height=9}
# replicate earlier overview plot but now with the calibrated delta values
# and with a higlight of the calibration ranges and which points are in range
peak_table_calibrated  %>% 
  # focus on identified peaks (comment out this line to see ALL peaks)
  #filter(!is.na(compound)) %>% 
  filter(compound %in% c("nC29", "nC31", "Cholestane (alpha-5)")) %>% 
  # visualize with convenience function iso_plot_data
  iso_plot_data(
    # choose x and y (multiple y possible)
    x = area.Vs, y = true_d2H_pred,
    # choose aesthetics
    color = in_range, shape = type, label = compound, size = 3,
    # decide what geoms to include
    points = TRUE
  ) %>% 
  # highlight calibration range
  iso_mark_calibration_range() +
  # further customize ggplot with a log scale x axis
  scale_x_log10() +
  # legend
  theme(legend.position = "bottom", legend.direction = "vertical")
```

### Standards

```{r "standards_7V", fig.width=7, fig.height=6}
# visualize how standard line up after calibration
peak_table_calibrated %>% 
  # focus on peaks in calibration
  filter(in_calib) %>% 
  # visualize
  iso_plot_data(
    # x and y
    x = true_d2H, y = true_d2H_pred, y_error = true_d2H_pred_se,
    # aesthetics
    color = compound, size = area.Vs,
    # geoms
    points = TRUE
  ) +
  # add 1:1 trendline
  geom_abline(slope = 1, intercept = 0)
```

### Data

#### Isotopic values

```{r "samples_7V", fig.width = 10, fig.height = 7}
# Warning: data outside the calibration range MUST be taken with a big
# grain of salt, especially at the low signal area/amplitude end
peak_table_calibrated %>% 
  # focus on samples
  filter(type == "sample") %>% 
  # focus on the compuonds we care about
  filter(compound %in% c("nC29", "nC31", "Cholestane (alpha-5)")) %>% 
  # focus on identified peaks (comment out this line to see ALL peaks)
  # if there's a lot of data, might need to hone in on a few at a time
  filter(!is.na(compound)) %>% 
  # visualize
  iso_plot_data(
    # x and y
    x = id1, y = true_d2H_pred, y_error = true_d2H_pred_se,
    # aesthetics
    color = in_range, size = rel_area,
    # geoms
    points = TRUE
  ) %>% 
  # mark calibration range (include optionally)
  iso_mark_calibration_range() +
  # add facet wrap
  facet_wrap(~compound, scales = "free_y") +
  # color palette (here example of manual: www.google.com/search?q=color+picker)
  # scale_color_manual(
  #   values = c("#984EA3", "#E41A1C", "#E41A1C", "#377EB8", "#FF7F00", "#4DAF4A")
  # ) +
  # clarify size scale
  scale_size_continuous(breaks = c(0.01, 0.05, 0.1, 0.2, 0.3), 
                        labels = function(x) paste0(100*x, "%")) +
  # plot labels
  labs(x = NULL, y = "d2H [permil]")

#ggplotly(ggplot2::last_plot() + theme(legend.position = "none"))


```

I made all my calculations of concentrations based on n-alkane C-31, all of the runs are "in range"... so this is good right?? for C29 there are only 4 samples out of range from all the runs I did... so doesn't seem to be that bad?? 

#### Internal Standard check

```{r}
#wasn't able to plot the mean so extracted from dataframe the number
internal_std <- peak_table_calibrated %>% 
  filter(type == "sample") %>% 
  filter(compound == "Cholestane (alpha-5)") 

y_value <- mean(internal_std$true_d2H_pred)
y_value_sd <- sd(internal_std$true_d2H_pred)
# plot IS only
peak_table_calibrated %>% 
  filter(type == "sample") %>% 
  filter(compound == "Cholestane (alpha-5)") %>% 
 iso_plot_data(
    #dt = internal_std,
    x = id1,
    y = true_d2H_pred,
    y_error = true_d2H_pred_se, 
    size = area.Vs, color = in_range,
    points = TRUE, lines = TRUE) + geom_hline(
    mapping = aes(yintercept = y_value)) 



print(paste("mean isotopic value of Cholestane (alpha-5): ", y_value))
print(paste("and the standard deviation value of Cholestane (alpha-5): ", y_value_sd))
#mean(internal_std$true_d2H_pred), mapping =  aes(yintercept =internal_std$true_d2H_pred))
#+
 # geom_hline(data = function(df) 
  #  df %>% group_by(panel) %>% 
 #     summarize(y_value = mean(y_value)),
#    mapping = aes(yintercept = y_value)) +
#  geom_label(data = function(df) 
 #   df %>% group_by(panel) %>% 
  #    summarize(id1 = sort(id1)[1], y_value_sd = sd(y_value), y_value = mean(y_value)),
  #  mapping = aes(color = NULL, label = sprintf("%.2f +/- %.2f", y_value, y_value_sd))
 # )

```


#### Relative abundances

```{r "abundances_7V", fig.width = 7, fig.height = 6, warning=FALSE}
# visualize relative abundances
peak_table_calibrated %>% 
  # focus on samples
  filter(type == "sample") %>% 
  filter(compound %in% c("nC29", "nC31", "nC33")) %>% 
  # focus on identified peaks (comment out this line to see ALL peaks)
  #filter(!is.na(compound)) %>% 
  # visualize
  iso_plot_data(
    # x and y
    x = id1, y = rel_area,
    # aesthetics
    fill = compound
  ) +
  # barchart
  geom_bar(stat = "identity") +
  # scales
  scale_y_continuous(labels = function(x) paste0(100*x, "%"), expand = c(0, 0)) +
  # plot labels
  labs(x = NULL, y = "Relative abundance (by area)")
```

#### Summary

```{r}
# generate data summary
peak_data <- 
  peak_table_calibrated %>% 
  # focus on identified peaks in the samples
  filter(type == "sample", !is.na(compound)) %>% 
  select(id1, compound, Analysis, 
         area.Vs, true_d2H_pred, true_d2H_pred_se, in_range) %>% 
  arrange(id1, compound, Analysis)
# summarize replicates
# this example data set does not contain any replicates but typically all
# analyses should in which case a statistical data summary can be useful
peak_data_summary <- 
  peak_data %>% 
  # here: only peaks within the area calibration range are included
  # you have to explicitly decide which peaks you trust if they are out of range
  filter(
    in_range %in% c("in range", "<'true_d2H_pred' range", ">'true_d2H_pred' range") |
      area.Vs > 7
  ) %>% 
  # summarize for each sample and compound
  group_by(id1, compound) %>% 
  iso_summarize_data_table(area.Vs, true_d2H_pred)
peak_data_summary %>% knitr::kable(d = 2)
```

## Export 7V

```{r}
# export the global calibration with all its information and data to Excel
global_calibs_with_ranges %>% 
 
  iso_export_calibration_to_excel(
   filepath = format(Sys.Date(), "%Y%m%d_d2H_waxes_soils_7V.xlsx"),
     # include data summary as an additional useful tab
     `data summary` = peak_data_summary
   )

```

## 10V Generate Calibrations (*)
```{r}
# define a global calibration across all standards
global_calibs <- 
  peak_table_0919_w_stds %>%
  # remove (most) problematic peaks to speed up calibration calculations
  # note: could additionally remove unidentified peaks if they are of no interest
  iso_remove_problematic_peak_mappings(remove_unidentified = FALSE) %>% 
  # prepare for calibration (no grouping to go across all analyses)
  iso_prepare_for_calibration() %>% 
  # run different calibrations
  iso_generate_calibration(
    model = c(
     # linear = lm(d2H ~ true_d2H), #these are all the different combinations of things you can correct for as a global claibration, linear is the standard one
      #with_rt = lm(d2H ~ true_d2H + rt), #because my samples have a systematic errror due to retention time, we applied this
      #with_datetime = lm(d2H ~ true_d2H + file_datetime),
     # with_rt_area_datetime = lm(d2H ~ true_d2H + file_datetime + rt + area2.Vs),
      #with_area_and_rt = lm(d2H ~ true_d2H + area2.Vs + rt), #it seems that this one is the best one as the retention time affects the area Vs and i need to correct for both
      with_area = lm(d2H ~ true_d2H + area2.Vs),
     with_area_divide = lm(d2H ~ true_d2H + (1/ area2.Vs)),
     with_area_cross_divide = lm(d2H ~ true_d2H * (1/ area2.Vs)),
     with_area_sqrt = lm(d2H ~ true_d2H + sqrt(area2.Vs)),
      with_area_cross_sqrt = lm(d2H ~ true_d2H * sqrt(area2.Vs)),
      with_area_cross = lm(d2H ~ true_d2H * area2.Vs)
    ),
    # specify which peaks to include in the calibration, here:
    # - all std_peaks (this filter should always be included!)
    # - standard peaks between 5 and 100 Vs
    # - only analyses with seed oxidation (same as all the samples)
    is_std_peak = is_std_peak & area.Vs > 10 & area.Vs < 100
  )
```
### Coefficients

```{r "global_calibration_coefficients", fig.width=7, fig.height=12}
# look at coefficients and summary
global_calibs %>% 
  # unnest calibration parameters
  iso_get_calibration_parameters(
    select_from_coefs = 
      c(term, estimate, SE = std.error, signif),
    select_from_summary = 
      c(fit_R2 = adj.r.squared, fit_RMSD = deviance, residual_df = df.residual)) %>%
  iso_remove_list_columns() %>% 
  arrange(term) %>% 
  knitr::kable(digits = 4)
# visualize coefficients for the different global calibrations
global_calibs %>% iso_plot_calibration_parameters(x = calib, color = signif)
```
according to this, I think the best calibration is "with_are_cross_sqrt"... is this ok? 

### Residuals
```{r "global_calibration_residuals", fig.width=8, fig.height=4}
global_calibs %>% 
  # pull out all peak data to including residuals
  iso_get_calibration_data(select = everything()) %>% 
  # focus on standard peaks included in the calibration
  filter(in_calib) %>% 
  # visualize
  iso_plot_data(
    # aesthetics
    x = compound, y = resid, color = calib, group = paste(Analysis, calib),
    # geoms
    lines = TRUE
  ) +
  # plot modifications
  facet_grid(. ~ calib) + theme(legend.position = "bottom")
```
based on the residuals, in general, they are pretty similar (I think? I don't see a huge change compared with what I saw with the carbon data)

### Pick global calibration
```{r}
# which calibration to use? can include multiple if desired to see the result

calib_to_use <- "with_area_cross_sqrt" #in this case I need to correct for  retention time (RT), AREA, and datetime? it seems to be the best calibration to use
```
### Apply global calibration (*)

```{r, cache=TRUE}
# note that depending on the number of data points, this may take a while
# for faster calculations, chose calculate_error = FALSE
global_calibs_applied <- 
  global_calibs %>% 
  # decide which calibration to apply based on 
  filter(calib %in% calib_to_use) %>% 
  # apply calibration indication what should be calcculated
  iso_apply_calibration(true_d2H, calculate_error = TRUE)
# calibration ranges
global_calibs_with_ranges <-
  global_calibs_applied %>% 
  # evaluate calibration range for the measured area.Vs and predicted d13C
  iso_evaluate_calibration_range(area.Vs, true_d2H_pred) 
# show calibration ranges
global_calibs_with_ranges %>% 
  iso_unnest_calibration_range() %>% 
  iso_remove_list_columns() %>% 
  knitr::kable(d = 2)
# create calibrated peak table
peak_table_calibrated <- global_calibs_with_ranges %>% 
  iso_unnest_data(select = everything())
```

## Evaluation

### Overview of all the data

```{r "data_overview_all", fig.width=7, fig.height=9}
# replicate earlier overview plot but now with the calibrated delta values
# and with a higlight of the calibration ranges and which points are in range
peak_table_calibrated  %>% 
  # focus on identified peaks (comment out this line to see ALL peaks)
  filter(!is.na(compound)) %>% 
  #filter(compound %in% c("nC29", "nC31", "Cholestane (alpha-5)")) %>% 
  # visualize with convenience function iso_plot_data
  iso_plot_data(
    # choose x and y (multiple y possible)
    x = area.Vs, y = true_d2H_pred,
    # choose aesthetics
    color = in_range, shape = type, label = compound, size = 3,
    # decide what geoms to include
    points = TRUE
  ) %>% 
  # highlight calibration range
  iso_mark_calibration_range() +
  # further customize ggplot with a log scale x axis
  scale_x_log10() +
  # legend
  theme(legend.position = "bottom", legend.direction = "vertical")
```

### Overview of C29, C31, and Cholestane

```{r "data_overview", fig.width=7, fig.height=9}
# replicate earlier overview plot but now with the calibrated delta values
# and with a higlight of the calibration ranges and which points are in range
peak_table_calibrated  %>% 
  # focus on identified peaks (comment out this line to see ALL peaks)
  #filter(!is.na(compound)) %>% 
  filter(compound %in% c("nC29", "nC31", "Cholestane (alpha-5)")) %>% 
  # visualize with convenience function iso_plot_data
  iso_plot_data(
    # choose x and y (multiple y possible)
    x = area.Vs, y = true_d2H_pred,
    # choose aesthetics
    color = in_range, shape = type, label = compound, size = 3,
    # decide what geoms to include
    points = TRUE
  ) %>% 
  # highlight calibration range
  iso_mark_calibration_range() +
  # further customize ggplot with a log scale x axis
  scale_x_log10() +
  # legend
  theme(legend.position = "bottom", legend.direction = "vertical")
```

### Standards

```{r "standards", fig.width=7, fig.height=6}
# visualize how standard line up after calibration
peak_table_calibrated %>% 
  # focus on peaks in calibration
  filter(in_calib) %>% 
  # visualize
  iso_plot_data(
    # x and y
    x = true_d2H, y = true_d2H_pred, y_error = true_d2H_pred_se,
    # aesthetics
    color = compound, size = area.Vs,
    # geoms
    points = TRUE
  ) +
  # add 1:1 trendline
  geom_abline(slope = 1, intercept = 0)
```

### Data

#### Isotopic values

```{r "samples", fig.width = 10, fig.height = 7}
# Warning: data outside the calibration range MUST be taken with a big
# grain of salt, especially at the low signal area/amplitude end
peak_table_calibrated %>% 
  # focus on samples
  filter(type == "sample") %>% 
  # focus on the compuonds we care about
  filter(compound %in% c("nC29", "nC31", "Cholestane (alpha-5)")) %>% 
  # focus on identified peaks (comment out this line to see ALL peaks)
  # if there's a lot of data, might need to hone in on a few at a time
  filter(!is.na(compound)) %>% 
  # visualize
  iso_plot_data(
    # x and y
    x = id1, y = true_d2H_pred, y_error = true_d2H_pred_se,
    # aesthetics
    color = in_range, size = rel_area,
    # geoms
    points = TRUE
  ) %>% 
  # mark calibration range (include optionally)
  iso_mark_calibration_range() +
  # add facet wrap
  facet_wrap(~compound, scales = "free_y") +
  # color palette (here example of manual: www.google.com/search?q=color+picker)
  # scale_color_manual(
  #   values = c("#984EA3", "#E41A1C", "#E41A1C", "#377EB8", "#FF7F00", "#4DAF4A")
  # ) +
  # clarify size scale
  scale_size_continuous(breaks = c(0.01, 0.05, 0.1, 0.2, 0.3), 
                        labels = function(x) paste0(100*x, "%")) +
  # plot labels
  labs(x = NULL, y = "d2H [permil]")

#ggplotly(ggplot2::last_plot() + theme(legend.position = "none"))


```

I made all my calculations of concentrations based on n-alkane C-31, all of the runs are "in range"... so this is good right?? for C29 there are only 4 samples out of range from all the runs I did... so doesn't seem to be that bad?? 

#### Internal Standard check

```{r}
#wasn't able to plot the mean so extracted from dataframe the number
internal_std <- peak_table_calibrated %>% 
  filter(type == "sample") %>% 
  filter(compound == "Cholestane (alpha-5)") 

y_value <- mean(internal_std$true_d2H_pred)
y_value_sd <- sd(internal_std$true_d2H_pred)
# plot IS only
peak_table_calibrated %>% 
  filter(type == "sample") %>% 
  filter(compound == "Cholestane (alpha-5)") %>% 
 iso_plot_data(
    #dt = internal_std,
    x = id1,
    y = true_d2H_pred,
    y_error = true_d2H_pred_se, 
    size = area.Vs, color = in_range,
    points = TRUE, lines = TRUE) + geom_hline(
    mapping = aes(yintercept = y_value)) 



print(paste("mean isotopic value of Cholestane (alpha-5): ", y_value))
print(paste("and the standard deviation value of Cholestane (alpha-5): ", y_value_sd))
#mean(internal_std$true_d2H_pred), mapping =  aes(yintercept =internal_std$true_d2H_pred))
#+
 # geom_hline(data = function(df) 
  #  df %>% group_by(panel) %>% 
 #     summarize(y_value = mean(y_value)),
#    mapping = aes(yintercept = y_value)) +
#  geom_label(data = function(df) 
 #   df %>% group_by(panel) %>% 
  #    summarize(id1 = sort(id1)[1], y_value_sd = sd(y_value), y_value = mean(y_value)),
  #  mapping = aes(color = NULL, label = sprintf("%.2f +/- %.2f", y_value, y_value_sd))
 # )

```


#### Relative abundances

```{r "abundances", fig.width = 7, fig.height = 6, warning=FALSE}
# visualize relative abundances
peak_table_calibrated %>% 
  # focus on samples
  filter(type == "sample") %>% 
  filter(compound %in% c("nC29", "nC31", "nC33")) %>% 
  # focus on identified peaks (comment out this line to see ALL peaks)
  #filter(!is.na(compound)) %>% 
  # visualize
  iso_plot_data(
    # x and y
    x = id1, y = rel_area,
    # aesthetics
    fill = compound
  ) +
  # barchart
  geom_bar(stat = "identity") +
  # scales
  scale_y_continuous(labels = function(x) paste0(100*x, "%"), expand = c(0, 0)) +
  # plot labels
  labs(x = NULL, y = "Relative abundance (by area)")
```

#### Summary

```{r}
# generate data summary
peak_data <- 
  peak_table_calibrated %>% 
  # focus on identified peaks in the samples
  filter(type == "sample", !is.na(compound)) %>% 
  select(id1, compound, Analysis, 
         area.Vs, true_d2H_pred, true_d2H_pred_se, in_range) %>% 
  arrange(id1, compound, Analysis)
# summarize replicates
# this example data set does not contain any replicates but typically all
# analyses should in which case a statistical data summary can be useful
peak_data_summary <- 
  peak_data %>% 
  # here: only peaks within the area calibration range are included
  # you have to explicitly decide which peaks you trust if they are out of range
  filter(
    in_range %in% c("in range", "<'true_d2H_pred' range", ">'true_d2H_pred' range") |
      area.Vs > 10
  ) %>% 
  # summarize for each sample and compound
  group_by(id1, compound) %>% 
  iso_summarize_data_table(area.Vs, true_d2H_pred)
peak_data_summary %>% knitr::kable(d = 2)
```

## Export 10V

```{r}
# export the global calibration with all its information and data to Excel
global_calibs_with_ranges %>% 
 
  iso_export_calibration_to_excel(
   filepath = format(Sys.Date(), "%Y%m%d_d2H_waxes_soils_10V.xlsx"),
     # include data summary as an additional useful tab
     `data summary` = peak_data_summary
   )

```


####corrected names for samples and export summary
```{r}
# data_samples_hand <- read.table("final_d2H_soils.txt", header = TRUE, sep = "\t")
# 
# data_summary_2 <- data_samples_hand %>% group_by(id1, compound) %>%
#  iso_summarize_data_table(area.Vs, true_d2H_pred)
```


 # Export


```{r}
# export the global calibration with all its information and data to Excel
#global_calibs_with_ranges %>% 
#  
# # iso_export_calibration_to_excel(
#    filepath = format(Sys.Date(), "%Y%m%d_d2H_waxes_soils.xlsx"),
#     # include data summary as an additional useful tab
#     `data summary` = peak_data_summary
#   )
# 
# #export data summary 
# global_calibs_with_ranges%>%
#  iso_export_calibration_to_excel(
#     filepath = format(Sys.Date(), "%Y%m%d_d2H_waxes_soils_corrected.xlsx"),
#     # include data summary as an additional useful tab
#     `data summary` = data_summary_2
#   )

```

